{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Spatial Action recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage import transform, filter\n",
    "from skimage.color import rgb2gray\n",
    "import sys, pylab, operator, csv\n",
    "import util\n",
    "import os\n",
    "import urllib\n",
    "import imageio\n",
    "import itertools\n",
    "import skimage.io\n",
    "import caffe\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "import visualisation\n",
    "import transformers\n",
    "import excitation_backprop\n",
    "import debug\n",
    "import beoid\n",
    "\n",
    "import cnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 110\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_root_path = \"/home/will/nets/vgg_16_ucf101/\"\n",
    "model_name = \"cuhk_action_spatial_vgg_16_split2\"\n",
    "\n",
    "deploy_prototxt_path = os.path.join(model_root_path, model_name + \"_deploy.prototxt\")\n",
    "caffemodel_path = os.path.join(model_root_path, model_name + \".caffemodel\")\n",
    "\n",
    "\n",
    "net = caffe.Net(deploy_prototxt_path,\n",
    "                caffemodel_path,\n",
    "                caffe.TEST)\n",
    "\n",
    "# The very last layer in the network (pre loss layer)\n",
    "topLayerName = 'fc8-1'\n",
    "topBlobName = net.top_names[topLayerName][0]\n",
    "secondTopLayerName = 'fc7'\n",
    "secondTopBlobName = net.top_names[secondTopLayerName][0]\n",
    "\n",
    "# This is the layer we'll stop at when excitation backpropping\n",
    "outputLayerName = 'pool3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug.filter_shapes(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop(image, size):\n",
    "    old_width = image.shape[0]\n",
    "    new_width = size[0]\n",
    "    assert old_width >= new_width\n",
    "    \n",
    "    old_height = image.shape[1]\n",
    "    new_height = size[1]\n",
    "    assert old_height >= new_height\n",
    "    \n",
    "    horizontal_crop = int(np.ceil((old_width - new_width) / 2))\n",
    "    vertical_crop = int(np.ceil((old_height - new_height) / 2))\n",
    "    \n",
    "    return image[\n",
    "        horizontal_crop:-horizontal_crop,\n",
    "        vertical_crop:-vertical_crop\n",
    "    ].reshape(*new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = \"/home/will/thesis/generated/ucf101/test-1/frames/\"\n",
    "image_path = os.path.join(data_root, \"v_BoxingPunchingBag_g07_c04/frame000005.jpg\")\n",
    "                        \n",
    "input_image = caffe.io.load_image(image_path)\n",
    "skimage.io.Image(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_size = (224, 224, 3)\n",
    "image = crop(input_image, new_size)\n",
    "\n",
    "skimage.io.Image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in net.params.keys():\n",
    "    weights = net.params[layer][0].data\n",
    "    biases = net.params[layer][1].data\n",
    "    \n",
    "    print(layer)\n",
    "\n",
    "    print(\"Biases:  [\", np.min(biases), \", \", np.max(biases), \"]\")\n",
    "    print(\"Weights: [\", np.min(weights), \", \", np.max(weights), \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eb = excitation_backprop.ExcitationBackprop(net, 'fc8-1', 'fc7', 'pool3')\n",
    "transformer = transformers.imagenet_transformer(net)\n",
    "preprocessed_image = transformer.preprocess('data', image)\n",
    "print(\"Input min: \", np.min(preprocessed_image))\n",
    "print(\"Input max: \", np.max(preprocessed_image))\n",
    "net.blobs['data'].data[...] = preprocessed_image.reshape(1, 3, 224, 224)\n",
    "out = net.forward(end = topLayerName)\n",
    "\n",
    "print(\"Output layer max:\", np.max(net.blobs[eb.top_blob_name].data))\n",
    "print(\"Output layer min:\", np.min(net.blobs[eb.top_blob_name].data))\n",
    "\n",
    "class_count = 101\n",
    "scores = net.blobs[eb.top_blob_name].data[0].reshape(class_count, -1).max(1).flatten() # pre-softmax scores\n",
    "class_ids = scores.argsort()[-3:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = map(lambda x: x, net.blobs)\n",
    "pooling_layers = [layer for layer in layers if  'pool' in layer]\n",
    "pooling_layers.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_grid(images, square=True):\n",
    "    image_count = len(images)\n",
    "    if square:\n",
    "        width = int(np.ceil(np.sqrt(image_count)))\n",
    "        height = width\n",
    "    else:\n",
    "        width = image_count\n",
    "        height = 1\n",
    "    \n",
    "    fig, axes = plt.subplots(height, width)\n",
    "    for i, image in enumerate(images):\n",
    "        axes.flat[i].imshow(image)\n",
    "        \n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "            \n",
    "    \n",
    "    return (fig, axes)\n",
    "\n",
    "def attention_map_grid(image, attention_maps, labels=None, square=True):\n",
    "    overlaid_attention_maps = list(map(\n",
    "        lambda attention_map: visualisation.overlay_attention_map(image, attention_map),\n",
    "        attention_maps\n",
    "    ))\n",
    "    (fig, axes) = image_grid(overlaid_attention_maps, square=square)\n",
    "    if labels is not None:\n",
    "        for (ax, label) in zip(axes.flat, labels):\n",
    "            ax.set_xlabel(label)\n",
    "            \n",
    "    return (fig, axes)\n",
    "\n",
    "attention_maps = []\n",
    "for pooling_layer in pooling_layers:\n",
    "    eb = excitation_backprop.ExcitationBackprop(net, 'fc8-1', 'fc7', pooling_layer)\n",
    "    attention_maps.append(eb.backprop(class_ids[0]))\n",
    "    \n",
    "(fig, _) = attention_map_grid(rgb2gray(image), attention_maps, pooling_layers, square=False)\n",
    "fig.set_size_inches(7, 2)\n",
    "fig.savefig(\"ebp-pooling-layer-sizes.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
